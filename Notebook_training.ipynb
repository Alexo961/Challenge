{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    ">**Random forest classifier è un algoritmo di classificazione che genera alberi decisionali casuali e splitta il dataset in tanti samples da dare in pasto a questi alberi (in modo tale da evitare l'overfitting).**\n",
    "\n",
    ">**L'algoritmo inoltre salva tutte le accuracy che vengono prodotte da questi alberi e restituisce una media di esse come accuracy finale dell' algoritmo**\n",
    "\n",
    "\n",
    ">>**Nella mia implementazione dell' algoritmo, assegno un n_estimator dinamico tra 1 a 100 (ho controllato se un numero superiore a 100 mi potesse aiutare , ma non è stato cosi :) ) il numero di stimatori mi dice a ogni iterazione quanti alberi casuali genera e di quanti ne fà la media**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = { 'Knn'  : KNeighborsClassifier() , 'DT' : DecisionTreeClassifier(criterion= 'entropy'), 'RF': RandomForestClassifier(), 'LR': LogisticRegression(penalty= 'l2',max_iter = 1000) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = { 'Knn'  : 0, 'DT' : 0, 'RF': 0, 'LR': 0 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features_lasso =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_y(dataset,target):\n",
    "        y= dataset[target]\n",
    "        X= dataset.drop([target],axis=1)\n",
    "        return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv):\n",
    "    dataset=pd.read_csv(csv)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chiavi(dataset):\n",
    "    for i in dataset:\n",
    "        print (\"La colonna :\",i,\"ha le chiavi\",dataset[i].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features selection \n",
    "> Eseguo un features selection provando  una Regolarizzazione di tipo l1 'Lasso' che mi abbate i pesi con un fattore di regolarizzazione da aggiungere alla **funzione di costo**\n",
    ">> $$R(\\boldsymbol{w}) = \\sum_l \\left | w_l \\right |$$\n",
    "\n",
    "> esso mi abbatte i pesi **w** usando una discesa del gradiente che penalizza in modulo i pesi (che si vanno a sommare alla **funzion. di costo**, e  quindi dando lo stesso equilibrio sia ai pesi grandi che ai pesi piccoli nella fase di training di minimizzazione della funzione.\n",
    "\n",
    ">Inoltre sperimento un abbattimento dei pesi anche servendomi di una Ridge regression la quale ha un fattore di regolarizzazione di tipo **l2 norm**  che abbatte i valori dei pesi piu grandi(ne fà il quadrato e li aggiunge alla Loss) piuttosto che quelli piccoli ( quelli tra 0 e 1 vengono rimpiccioliti con il quadrato) sempre usando una discesa del gradiente e facendo la somma di tutti i pesi del vettore **W**\n",
    ">> $$R(\\boldsymbol{w}) = \\sum_l  w_l^2 $$\n",
    "\n",
    ">Il costo della ridge con aggiunta del fattore di regolazione **l2 norm** può essere riassunta come segue\n",
    "\n",
    ">> $$  CostoRidge(w) = RSS (w) +\\lambda R(w)$$\n",
    "\n",
    ">Il costo dell ridge ( o possiamo chiamarla anche **Loss Function** ) non è nient' altro che il costo della funzione di costo , che nell' esempio è la RSS sommato a un **lambda** più questo fattore di regolarizzazione.\n",
    "Il coeff. **lambda** è un coefficiente di smorzamento o tuning e va a fare appunto tuning dei parametri dando sterzate più o meno forti a ogni iterazione nell' aggiornamento dei pesi nella discesa del gradiente.\n",
    "\n",
    ">**La Ridge è molto più efficente anche con pochi campioni di training e riduce l' overfitting**\n",
    "\n",
    ">Uso per fare tutto ciò un meta_trasformatore chiamto SelectFromModel a cui serve uno stimatore passatogli come parametro per restituire con il metodo .get_support() una lista di booleani che mi corrispondono alle features da scegliere oppure no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_selection(X,y,X_test,alpha):\n",
    "    #Ridge= Ridge(alpha =0.01,random_state = 0,max_iter =100).fit(X,y)\n",
    "    #selector = SelectFromModel(Ridge, prefit =True) \n",
    "\n",
    "    \n",
    "    selector = SelectFromModel(Lasso(max_iter = 1000, alpha = alpha,random_state = 0))\n",
    "    selector.fit(X,y)\n",
    "    \n",
    "    return X[X.columns[selector.get_support()]],X_test[X_test.columns[selector.get_support()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Faccio 50 iterazioni aumentando gli estimatori del RandomClassifier a ogni iterazione**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_iter(X_train,X_test,y_train,y_test,disegna):\n",
    "    accuracy_RF = []\n",
    "    for i in range(1,10):\n",
    "        forest = RandomForestClassifier(n_estimators = i, random_state = 0)\n",
    "        forest.fit(X_train,y_train)\n",
    "        accuracy_RF.append(forest.score(X_test,y_test))\n",
    "   \n",
    "    if(disegna ==1):\n",
    "        plt.plot(np.arange(1,len(accuracy_RF)+1),accuracy_RF,label ='Random Forest' )\n",
    "    \n",
    "    max_accuracy = np.max(accuracy_RF)\n",
    "    max_index = 0\n",
    "    for j in range(0,len(accuracy_RF)):\n",
    "    \n",
    "        if(accuracy_RF[j]== max_accuracy):\n",
    "            max_index=j+1\n",
    "            if(disegna==1):\n",
    "                print (\"L'accuracy massima del random forest è con :\",max_index, \"estimatori\")\n",
    "                print (\"L'accuracy massima del random forestè :\",max_accuracy,\"\\n\")\n",
    "            return max_accuracy,RandomForestClassifier(n_estimators = max_index , random_state = 0)\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Faccio 500 iterazioni aumentando la profondità dell' albero ad ognuna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DT_iter (X_train,X_test,y_train,y_test,disegna):\n",
    "    accuracy_DT = []\n",
    "    for i in range(1,10):\n",
    "        tree = DecisionTreeClassifier(criterion= 'entropy',max_depth = i+2, random_state = 0)\n",
    "        tree.fit(X_train,y_train)\n",
    "        accuracy_DT.append(tree.score(X_test,y_test))\n",
    "    \n",
    "    if(disegna ==1):\n",
    "        plt.plot(np.arange(1,len(accuracy_DT)+1),accuracy_DT,label = 'DecisionTreeclassifier')\n",
    "    \n",
    "    max_accuracy_DT = np.max(accuracy_DT)\n",
    "    max_index_DT = 0\n",
    "    for j in range(0,len(accuracy_DT)):\n",
    "    \n",
    "          if(accuracy_DT[j]== max_accuracy_DT):\n",
    "            max_index_DT=j+3\n",
    "            if(disegna==1):\n",
    "                print (\"L'accuracy massima del DT è con profondità :\",max_index_DT)\n",
    "                print (\"L'accuracy massima del DT è :\",max_accuracy_DT)\n",
    "            return max_accuracy_DT, DecisionTreeClassifier(criterion= 'entropy',max_depth = max_index_DT, random_state = 0)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salvo le accuracy dei vari modelli migliori trovati nelle precedenti elaborazioni**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(X_train,X_test,y_train,y_test,disegna):\n",
    "    for i in model.keys():\n",
    "        if(i == 'RF'):\n",
    "            \n",
    "            max_accuracy,modello_RF = RF_iter(X_train,X_test,y_train,y_test,disegna)\n",
    "            model[i] = modello_RF\n",
    "            accuracy[i]= max_accuracy\n",
    "           \n",
    "        elif(i == 'DT'):\n",
    "            accuratezza, modello_DT = DT_iter(X_train,X_test,y_train,y_test,disegna)\n",
    "          \n",
    "            model[i] = modello_DT\n",
    "            \n",
    "            \n",
    "            accuracy[i]=accuratezza\n",
    "           \n",
    "        else:\n",
    "            modello = model[i]\n",
    "           \n",
    "            modello.fit(X_train,y_train)\n",
    "            if(disegna == 1):\n",
    "                print(\"per \",i,\"l'accuratezza è\",modello.score(X_test,y_test))\n",
    "            accuracy[i]=modello.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modello_con_maggiore_accuracy():\n",
    "    accuracy_finale =(max(list(accuracy.values())))\n",
    "    for i in accuracy.keys():\n",
    "        if(accuracy.get(i)== accuracy_finale):\n",
    "            modello_finale = i\n",
    "            return accuracy_finale,(model.get(modello_finale)),modello_finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def da_plottare(modello,X_train,y_train,X_test,y_test,title):\n",
    "    labels = [' no', ' yes']\n",
    "    modello.fit(X_train,y_train)\n",
    "    plot_confusion_matrix(modello, X_test, y_test,  cmap=plt.cm.YlGn,display_labels=labels ) #, normalize='false'\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizza(dataset):\n",
    "     for i in dataset:\n",
    "        print(\"colonna :\",i,\"conta\", dataset[i].nunique(),\"valori di chiavi diversi\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_senza_fselection(X_train,y_train,X_test,y_test):\n",
    "    disegna = 0\n",
    "    lista_acc = []\n",
    "    lista_alpha = [0.001,0.01]\n",
    "    for i in lista_alpha:\n",
    "        \n",
    "        X_new_train,X_new_test = features_selection(X_train,y_train,X_test,i)\n",
    "        if ((X_new_train.shape[0]!= 0)&(X_new_test.shape[0]!= 0)):\n",
    "            model_evaluation(X_new_train, X_new_test, y_train, y_test,disegna)\n",
    "            accuracy_end_new,modello_new,titolo_new = modello_con_maggiore_accuracy()\n",
    "            print(\"Numero colonne usate all iterazione di alpha = :\",i,\"è:\", len(X_new_test.columns),\" e l'accuracy è :\",accuracy_end_new)\n",
    "            lista_acc.append(accuracy_end_new)\n",
    "    \n",
    "    \n",
    "    max_acc_lasso = max(lista_acc)\n",
    "    \n",
    "    \n",
    "    model_evaluation(X_train, X_test, y_train, y_test,disegna)\n",
    "    accuracy_end,modello,titolo = modello_con_maggiore_accuracy()\n",
    "    print(\"L'accuracy massima senza fselection è :\",accuracy_end,\" e il numero colonne di X_train è\",len(X_train.columns))\n",
    "    if(max_acc_lasso >= accuracy_end):\n",
    "       \n",
    "        for j in range(0,len(lista_acc)):\n",
    "          \n",
    "            if(lista_acc[j]==max_acc_lasso):\n",
    "                \n",
    "                max_alpha_lasso = lista_alpha[j]\n",
    "        print(\"E' STATA  SCELTA LA FSELECTION DI TIPO LASSO CON ALPHA :\",max_alpha_lasso)\n",
    "        X_train,X_test = features_selection(X_train,y_train,X_test,max_alpha_lasso)\n",
    "       \n",
    "        disegna = 1\n",
    "        print(\"Numero colonne usate nel finale :\", X_train.columns.to_list())\n",
    "        model_evaluation(X_train, X_test, y_train, y_test,disegna)\n",
    "        accuracy_end,modello,titolo = modello_con_maggiore_accuracy()\n",
    "        return accuracy_end,modello,titolo,X_train,X_test\n",
    "    else:\n",
    "        print(\"NON E STATA SCELTA LA FSELECTION \")\n",
    "        \n",
    "        disegna = 1\n",
    "        model_evaluation(X_train, X_test, y_train, y_test,disegna)\n",
    "        accuracy_end,modello,titolo = modello_con_maggiore_accuracy()\n",
    "        return accuracy_end,modello,titolo,X_train,X_test\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(): \n",
    "    Train = load_data('train.csv')\n",
    "    Test = load_data('test.csv')\n",
    "    return Train,Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_train_y_train(target):  \n",
    "    y_train = Train[target]\n",
    "    X_train = Train.drop(columns = target)\n",
    "  \n",
    "    return X_train,y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_test_y_test(target): \n",
    "    y_test = Test[target]\n",
    "    X_test = Test.drop(columns = target)\n",
    "   \n",
    "    return  X_test,y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elaboro il dataset e sostituisco una lista di caratteri spuri con NaN a cui poi posso interagire semplicemente**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elabora_dataset_e_pulisci(dataset):\n",
    "    spuri = ['?','#','@',',','.',' ']\n",
    "    \n",
    "    \n",
    "    for i in dataset.columns:\n",
    "        for j in spuri: \n",
    "            if( j in dataset[i].to_list()):\n",
    "                dataset[i]=dataset[i].replace(j,np.NaN)\n",
    "            \n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cancello le colonne che hanno una numerosità di valori come quella degli elementi del dataset poichè non danno alcuna informazione a livello di previsione**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colonne_id(dataset):\n",
    "    \n",
    "    for i in dataset:\n",
    "       \n",
    "        \n",
    "        if((dataset[i].nunique() == dataset.index.size)):#sara un id o comunque non serve\n",
    "            dataset = dataset.drop(columns=[i])\n",
    "       \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning\n",
    ">**Applico una tecnica di Binning a determinate colonne trovate con determinate proporzioni.  Questa tecnica, mi crea un intervallo invece di avere un numero float64 o int64 nudo e crudo, credo che avere un intervallo sia più descrittivo durante il processo di previsione di un pattern predittivo**\n",
    "\n",
    "\n",
    "\n",
    ">**Ho deciso di divedere in massimo 5 intervalli sul massimo delle colonne del valore del train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Binning(dataset,col, max_valore_col_train): #la Uso per Age , per Scheduled_giorno\n",
    "    lista = []\n",
    "    if(dataset[col].dtypes in ['int64','float64']):\n",
    "        \n",
    "        \n",
    "        for j in range(dataset[col].shape[0]):\n",
    "            \n",
    "            if(dataset[col].loc[j] <= int((1/5)*max_valore_col_train)):\n",
    "                lista.append(0)\n",
    "                \n",
    "\n",
    "            elif( (dataset[col].loc[j] > int((1/5)*max_valore_col_train)) & (dataset[col].loc[j] <= int((2/5)*max_valore_col_train)) ):\n",
    "                lista.append(1)\n",
    "\n",
    "            elif((dataset[col].loc[j] > int((2/5)*max_valore_col_train)) & (dataset[col].loc[j] <= int((3/5)*max_valore_col_train))):\n",
    "                lista.append(2)\n",
    "\n",
    "            elif((dataset[col].loc[j] > int((3/5)*max_valore_col_train)) & (dataset[col].loc[j] <= int((4/5)*max_valore_col_train))):\n",
    "                lista.append(3)\n",
    "\n",
    "            elif(dataset[col].loc[j] > int((4/5)*max_valore_col_train)):\n",
    "                lista.append(4)\n",
    "    \n",
    "    dataset[\"_\"+ col +\"_interval\"] = pd.DataFrame(lista)\n",
    "    dataset = dataset.drop(columns = col) \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RIMOZIONE DEI VALORI NULL O IMPUTAZIONE\n",
    ">>**Scelgo di rimuovere i valori null dalla tabella o farne imputazione a seconda della numerosità di questi valori, se il numero di valori nulli non supera 1/100 esimo del numero di dati , ne faccio imputazione , altrimenti eseguo una cancellazione delle righe con quei valori**\n",
    "\n",
    ">>**Faccio ciò perchè reputo che fare un imputazione su un numero elevato di datapoint sostituendo i valori nulli con la media o il termine più frequente, mi comprometterebbe un inquinamento del dataset, compromettendo l' analisi dell pattern che l'algoritmo cerca di prevedere.**\n",
    "## Imputazione\n",
    ">>**L' imputazione è un processo di sotituzione di valori nulli all' interno di un dataset. In particolare esso si basa sulla sostituzione di valori numerici tramite valore medio della stessa features e sostituzione di valori categorici tramite il valore più frequente sempre della stessa features. Ci sono molti altri modi di sostituze .**\n",
    "\n",
    ">>**Mi servo della classe SimpleImputer a cui passo come parametro la strategia con cui fare imputazione.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_imputer= SimpleImputer(strategy = 'mean')\n",
    "c_imputer = SimpleImputer(strategy = 'most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rimuovi_null_o_imputazione_train(dataset):\n",
    "    categorical_features_column= pd.DataFrame()\n",
    "    numerical_features_column= pd.DataFrame()\n",
    "   \n",
    "    for i in dataset:\n",
    "        \n",
    "        if(dataset[i].isnull().sum() >0):\n",
    "           \n",
    "            if(dataset[i].isnull().sum() >= ((1/100)*dataset.index.size)):\n",
    "                print(\"HO RIMOSSO LE RIGHE DELLA COLONNA\",i,\"DEL DATASET\")\n",
    "                dataset = dataset.dropna(subset=[i])\n",
    "                dataset = dataset.reset_index()[dataset.columns]\n",
    "               \n",
    "            else:\n",
    "                print(\"HO FATTO IMPUTAZIONE SU \" ,i,\"DEL DATASET\")\n",
    "                #colonna categorica\n",
    "                if(dataset[i].dtypes == object ):\n",
    "                    categorical_features_column = dataset[i]\n",
    "                else:\n",
    "                    numerical_features_column = dataset[i]\n",
    "                    # print(categorical_features.columns)\n",
    "                    # print(numerical_features.columns)\n",
    "               \n",
    "\n",
    "                if(categorical_features_column.empty == False):\n",
    "                    categorical_features_2 = pd.DataFrame(c_imputer.fit_transform(pd.DataFrame(categorical_features_column)))\n",
    "                   \n",
    "                    categorical_features_2.rename_axis(i)\n",
    "                    dataset[i]= categorical_features_2\n",
    "\n",
    "                else:\n",
    "                    numerical_features_2 = pd.DataFrame(n_imputer.fit_transform(pd.DataFrame(numerical_features_column)))\n",
    "                    \n",
    "                    numerical_features_2.rename_axis(i)\n",
    "                    dataset[i]= numerical_features_2\n",
    "    return dataset        \n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding dei dati\n",
    ">**Uso labelEncoder() che mi trasforma tutte le features categoriche in numeriche assegnando i numeri R positivi (da 0 a più infinito) a ogni valore categorico o ( intervallo del Binning) assegnando in ordine alphanumerico**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(dataset):\n",
    "    \n",
    "    for i in dataset:\n",
    "        encoder.fit(dataset[i])\n",
    "        dataset[i]= encoder.transform(dataset[i])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Faccio il fit sul train e poi trasformo il test con il fit del train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_prova(Train,Test,encoder):\n",
    "    print(encoder)\n",
    "    for i in Train:\n",
    "        if(Train[i].dtypes == 'object'):\n",
    "            print (i)\n",
    "            encoder.fit(Train[i])\n",
    "        \n",
    "            Train[i]=encoder.transform(Train[i])\n",
    "            Test[i]=encoder.transform(Test[i])\n",
    "    return Train,Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Faccio la stessa pila trasformativa avuta nel train per l 'altro notebook( lì è presente una spiegazione dei metodi usati). Essa mi servirà per trasformare il test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cancella_colonne(Train,Test):\n",
    "    for col in Test.columns:\n",
    "       \n",
    "        if(Test[col].name not in Train.columns.to_list()):\n",
    "            \n",
    "            Test=Test.drop(columns = col)\n",
    "    return Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_dataset(Train,Test):\n",
    "    data = pd.concat([Train,Test],axis=0)\n",
    "    data.reset_index()[data.columns]\n",
    "    #data = pipeline(data)\n",
    "    data = encoding(data)\n",
    "   \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lav_dataset(data,righe_train):\n",
    "    train_percent = int((80*data.shape[0])/100)\n",
    "   \n",
    "    print(\"Train Percent\",train_percent)\n",
    "    \n",
    "    Train = data.iloc[:righe_train-1]\n",
    "    Test = data.iloc[righe_train:]\n",
    "    return Train,Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(dataset,val_Age,val_attesa,val_Scheduled,val_Appo):\n",
    "    elabora_dataset_e_pulisci(dataset)\n",
    "  \n",
    "    dataset = rimuovi_null_o_imputazione_train(dataset)#facendolo prima sul train e poi sul test, esso si addestra sul test\n",
    "\n",
    "     \n",
    "    dataset = colonne_id(dataset)\n",
    "    \n",
    "    \n",
    "    dataset = Binning(dataset,'Age',val_Age)\n",
    "    print(dataset.info())\n",
    "    dataset = Binning(dataset,'attesa_giorni',val_attesa)\n",
    "    #dataset = Binning_qc(dataset,'Scheduled_ora_precisa',3)\n",
    "    dataset = Binning(dataset,'Scheduled_giorno',val_Scheduled)\n",
    "    dataset = Binning(dataset,'Appointment_giorno',val_Appo)\n",
    "    #dataset = Binning_qcut(dataset,'Scheduled_mese',2)\n",
    "    #dataset = Binning_qcut(dataset,'Appointment_giorno',2)\n",
    "    #dataset = Binning_qcut(dataset,'attesa_mese',3)\n",
    "    #dataset  = encoding(dataset)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lavorazione(dataset):\n",
    "    elabora_dataset_e_pulisci(dataset)\n",
    "    \n",
    "    Scheduled_anno = []\n",
    "    Scheduled_mese=[]\n",
    "    Scheduled_giorno=[]\n",
    "    Scheduled_ora_precisa=[]\n",
    "    Scheduled_ora = [ ]\n",
    "    for i in range(dataset['ScheduledDay'].shape[0]):\n",
    "        data,ora = dataset['ScheduledDay'].loc[i].split('T')\n",
    "        anno,mese,giorno = data.split('-')\n",
    "        Scheduled_anno.append(int(anno))\n",
    "        Scheduled_mese.append(int(mese))\n",
    "        Scheduled_giorno.append(int(giorno))\n",
    "        orario,z = ora.split('Z')\n",
    "        Scheduled_ora.append(orario)\n",
    "        orario_preciso,minuti,secondi=orario.split(':')\n",
    "        Scheduled_ora_precisa.append(int(orario_preciso))\n",
    "        \n",
    "       \n",
    "    dataset['Scheduled_mese'] = pd.DataFrame(Scheduled_mese)\n",
    "    dataset['Scheduled_giorno'] = pd.DataFrame(Scheduled_giorno)\n",
    "    dataset = dataset.drop(columns = ['ScheduledDay'])\n",
    "    dataset['Scheduled_ora_precisa'] = pd.DataFrame(Scheduled_ora_precisa)\n",
    "    \n",
    "    Appointment_mese=[]\n",
    "    Appointment_giorno=[]\n",
    "    Appointment_anno=[]\n",
    "    for j in range(dataset['AppointmentDay'].shape[0]):\n",
    "        data_1,ora_1 = dataset['AppointmentDay'].loc[j].split('T')\n",
    "        anno_1,mese_1,giorno_1 = data_1.split('-')\n",
    "        Appointment_mese.append(int(mese_1))\n",
    "        Appointment_giorno.append(int(giorno_1))\n",
    "        Appointment_anno.append(int(anno_1))\n",
    "      \n",
    "    dataset['Appointment_mese'] = pd.DataFrame(Appointment_mese)\n",
    "    dataset['Appointment_giorno'] = pd.DataFrame(Appointment_giorno)\n",
    "    dataset = dataset.drop(columns = ['AppointmentDay'])\n",
    "   \n",
    "    attesa_mese=[]\n",
    "    for h in dataset.index:\n",
    "        if(Scheduled_anno[h]==Appointment_anno[h]):\n",
    "            attesa_mese.append(abs( Appointment_mese[h] - Scheduled_mese[h]))\n",
    "        elif(Scheduled_anno[h]<Appointment_anno[h]):\n",
    "            attesa_mese.append(abs((Appointment_mese[h]+(12*abs((Appointment_anno[h]-Scheduled_anno[h])) ))- Scheduled_mese[h]))\n",
    "    dataset['attesa_mese']= pd.DataFrame(attesa_mese)\n",
    "        \n",
    "    attesa_giorni=[]\n",
    "    for h in dataset.index:\n",
    "        if((Scheduled_anno[h]==Appointment_anno[h])&(attesa_mese[h]==0)):\n",
    "            attesa_giorni.append(abs((Appointment_giorno[h]-Scheduled_giorno[h]) ))\n",
    "        elif((Scheduled_anno[h]==Appointment_anno[h])&(attesa_mese[h]!=0)):\n",
    "             attesa_giorni.append(abs((Appointment_giorno[h])+(attesa_mese[h]*30) ))\n",
    "        \n",
    "        elif((Scheduled_anno[h]< Appointment_anno[h])&(attesa_mese[h]==12)):\n",
    "             attesa_giorni.append(abs((Appointment_giorno[h]-Scheduled_giorno[h])+365*abs((Appointment_anno[h]-Scheduled_anno[h]))) )\n",
    "            \n",
    "        else:\n",
    "            attesa_giorni.append(abs(365*abs((Appointment_anno[h]-Scheduled_anno[h]))+abs(30*abs((Appointment_mese[h]-Scheduled_mese[h])))-abs(Scheduled_giorno[h])))\n",
    "            \n",
    "    dataset['attesa_giorni']= pd.DataFrame(attesa_giorni)\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "        \n",
    "        \n",
    "    \n",
    "   \n",
    "    \n",
    "    #QUI DROPPO LE COLONNE\n",
    "    \n",
    "    dataset = dataset.drop(columns = ['PatientId'])\n",
    "    dataset = dataset.drop(columns = ['AppointmentID'])\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70736 entries, 0 to 70735\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   PatientId       70736 non-null  float64\n",
      " 1   AppointmentID   70736 non-null  int64  \n",
      " 2   Gender          70736 non-null  object \n",
      " 3   ScheduledDay    70736 non-null  object \n",
      " 4   AppointmentDay  70736 non-null  object \n",
      " 5   Age             70736 non-null  int64  \n",
      " 6   Neighbourhood   70736 non-null  object \n",
      " 7   Scholarship     70736 non-null  int64  \n",
      " 8   Hipertension    70736 non-null  int64  \n",
      " 9   Diabetes        70736 non-null  int64  \n",
      " 10  Alcoholism      70736 non-null  int64  \n",
      " 11  Handcap         70736 non-null  int64  \n",
      " 12  SMS_received    70736 non-null  int64  \n",
      " 13  No-show         70736 non-null  object \n",
      "dtypes: float64(1), int64(8), object(5)\n",
      "memory usage: 7.6+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17685 entries, 0 to 17684\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   PatientId       17685 non-null  float64\n",
      " 1   AppointmentID   17685 non-null  int64  \n",
      " 2   Gender          17685 non-null  object \n",
      " 3   ScheduledDay    17685 non-null  object \n",
      " 4   AppointmentDay  17685 non-null  object \n",
      " 5   Age             17685 non-null  int64  \n",
      " 6   Neighbourhood   17685 non-null  object \n",
      " 7   Scholarship     17685 non-null  int64  \n",
      " 8   Hipertension    17685 non-null  int64  \n",
      " 9   Diabetes        17685 non-null  int64  \n",
      " 10  Alcoholism      17685 non-null  int64  \n",
      " 11  Handcap         17685 non-null  int64  \n",
      " 12  SMS_received    17685 non-null  int64  \n",
      " 13  No-show         17685 non-null  object \n",
      "dtypes: float64(1), int64(8), object(5)\n",
      "memory usage: 1.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Train,Test = load_file()\n",
    "print(Train.info())\n",
    "print(Test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Train = lavorazione(Train)\n",
    "Test = lavorazione(Test)\n",
    "Test = cancella_colonne(Train,Test)#per sicurezza\n",
    "#print(Train.info())\n",
    "#print(Test.info())\n",
    "#chiavi(Train)\n",
    "#chiavi(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La colonna : Gender ha le chiavi ['F' 'M']\n",
      "La colonna : Age ha le chiavi [ 44  11  46  75  83   6  49   0  28   3  20  43  71  63  35  21  22  62\n",
      "  48  76  77  37  10  25  47  36   2  19  29   7  15  39  33  23  58  38\n",
      "  17  27  12  67   9  41  53  65  30  68   1  72  50  24  70  52  59   5\n",
      "  51  26  13  14  60  56  66  61  16  42  80  34  54  78  45  40  82  18\n",
      "  69  79  57   8   4  98  86  85  64  90  81  32  92  55  73  31  74  84\n",
      "  97  89  88  87  91  93 100  95  94 102  96 115  99]\n",
      "La colonna : Neighbourhood ha le chiavi ['CARATOÍRA' 'MARIA ORTIZ' 'JARDIM CAMBURI' 'JESUS DE NAZARETH'\n",
      " 'SANTA MARTHA' 'CONQUISTA' 'SANTO ANTÔNIO' 'RESISTÊNCIA' 'SANTA TEREZA'\n",
      " 'ANDORINHAS' 'CENTRO' 'GURIGICA' 'ROMÃO' 'SÃO CRISTÓVÃO'\n",
      " 'ILHA DO PRÍNCIPE' 'CRUZAMENTO' 'REPÚBLICA' 'VILA RUBIM' 'JOANA D´ARC'\n",
      " 'ITARARÉ' 'JARDIM DA PENHA' 'BENTO FERREIRA' 'MATA DA PRAIA' 'JABOUR'\n",
      " 'MÁRIO CYPRESTE' 'NOVA PALESTINA' 'GOIABEIRAS' 'DA PENHA' 'FONTE GRANDE'\n",
      " 'BONFIM' 'FORTE SÃO JOÃO' 'DO MOSCOSO' 'SANTOS DUMONT' 'DO CABRAL'\n",
      " 'ILHA DAS CAIEIRAS' 'REDENÇÃO' 'SANTO ANDRÉ' 'DO QUADRO' 'PARQUE MOSCOSO'\n",
      " 'TABUAZEIRO' 'ILHA DE SANTA MARIA' 'SANTA LÚCIA' 'MORADA DE CAMBURI'\n",
      " 'PRAIA DO SUÁ' 'GRANDE VITÓRIA' 'SÃO PEDRO' 'BELA VISTA' 'SÃO JOSÉ'\n",
      " 'PIEDADE' 'SÃO BENEDITO' 'SANTA CECÍLIA' 'MARUÍPE' 'SANTOS REIS'\n",
      " 'BARRO VERMELHO' 'ENSEADA DO SUÁ' 'INHANGUETÁ' 'CONSOLAÇÃO'\n",
      " 'SOLON BORGES' 'HORTO' 'SANTA CLARA' 'SANTA LUÍZA' 'MONTE BELO'\n",
      " 'ESTRELINHA' 'JUCUTUQUARA' 'FRADINHOS' 'DE LOURDES' 'ARIOVALDO FAVALESSA'\n",
      " 'SEGURANÇA DO LAR' 'PRAIA DO CANTO' 'ILHAS OCEÂNICAS DE TRINDADE'\n",
      " 'BOA VISTA' 'ILHA DO BOI' 'SANTA HELENA' 'COMDUSA' 'UNIVERSITÁRIO'\n",
      " 'NAZARETH' 'ANTÔNIO HONÓRIO' 'PONTAL DE CAMBURI' 'ILHA DO FRADE'\n",
      " 'AEROPORTO' 'PARQUE INDUSTRIAL']\n",
      "La colonna : Scholarship ha le chiavi [0 1]\n",
      "La colonna : Hipertension ha le chiavi [0 1]\n",
      "La colonna : Diabetes ha le chiavi [0 1]\n",
      "La colonna : Alcoholism ha le chiavi [0 1]\n",
      "La colonna : Handcap ha le chiavi [0 1 2 3 4]\n",
      "La colonna : SMS_received ha le chiavi [0 1]\n",
      "La colonna : No-show ha le chiavi ['Yes' 'No']\n",
      "La colonna : Scheduled_mese ha le chiavi [ 5  4  3  6  2 12  1 11]\n",
      "La colonna : Scheduled_giorno ha le chiavi [10 12 28 31 13  2  9  4 11 18 30 17  6 29 19  1 24 20 25 16  7 23 26  5\n",
      "  8  3 15 27 14 21 22]\n",
      "La colonna : Scheduled_ora_precisa ha le chiavi [ 9 10  8 14 15 13 11 16  7 17 12 18  6 19 20 21]\n",
      "La colonna : Appointment_mese ha le chiavi [5 6 4]\n",
      "La colonna : Appointment_giorno ha le chiavi [17 16  6  1 19  9  2 20 18 11 30 25 10 29  3  7 24  4 13  8 31 12  5 14]\n",
      "La colonna : attesa_mese ha le chiavi [0 1 2 3 5 4 6]\n",
      "La colonna : attesa_giorni ha le chiavi [  7  46   4  66  31   6   0   2   5  36   1  32  77  14  40  17  50  34\n",
      "  47  33  37  16  54  78  41   3  12  38  13  20  28  39   9  65   8  11\n",
      "  62  35  42  49  29 110  24  61  63  48  55 102  59  15  43  21 103  71\n",
      "  68  10  90 567  60  89 106  70  76  19  64  93 107  26  67  72  25  18\n",
      "  22  85 119 126 151  69  73  79  96  80 128  92  91  27 115 100 132  23\n",
      "  95 139  84 136 108 530 109 114  94  98 123 122 101 131 538 121  99 537\n",
      " 561 156  97 129 150 535 125]\n"
     ]
    }
   ],
   "source": [
    "chiavi(Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Facendo partire l' encoder prima sul training e poi sul test e usando lo stesso modello di encoder, faccio si che l' encoding, si focalizzi solo sul train e poi da quello che ha capito dal trein faccia l' encoding del test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70736 entries, 0 to 70735\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   Gender                 70736 non-null  object\n",
      " 1   Neighbourhood          70736 non-null  object\n",
      " 2   Scholarship            70736 non-null  int64 \n",
      " 3   Hipertension           70736 non-null  int64 \n",
      " 4   Diabetes               70736 non-null  int64 \n",
      " 5   Alcoholism             70736 non-null  int64 \n",
      " 6   Handcap                70736 non-null  int64 \n",
      " 7   SMS_received           70736 non-null  int64 \n",
      " 8   No-show                70736 non-null  object\n",
      " 9   Scheduled_mese         70736 non-null  int64 \n",
      " 10  Scheduled_giorno       70736 non-null  int64 \n",
      " 11  Scheduled_ora_precisa  70736 non-null  int64 \n",
      " 12  Appointment_mese       70736 non-null  int64 \n",
      " 13  Appointment_giorno     70736 non-null  int64 \n",
      " 14  attesa_mese            70736 non-null  int64 \n",
      " 15  attesa_giorni          70736 non-null  int64 \n",
      " 16  _Age_interval          70736 non-null  int64 \n",
      "dtypes: int64(14), object(3)\n",
      "memory usage: 9.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#QUI PRIMA LAVORO SU TRAIN E TEST E POI UNISCO--> ENCODING E RISPLITTO\n",
    "\n",
    "\n",
    "max_Age = np.max(Train['Age'])\n",
    "max_attesa = np.max(Train['attesa_giorni'])\n",
    "max_schedule = np.max(Train['Scheduled_giorno'])\n",
    "max_Appo = np.max(Train['Appointment_giorno'])\n",
    "Train= pipeline(Train,max_Age,max_attesa,max_schedule,max_Appo)\n",
    "Test = pipeline(Test,max_Age,max_attesa,max_schedule,max_Appo)\n",
    "chiavi(Train)\n",
    "\n",
    "#numero_righe_train = Train.shape[0]#dato che poi passerò per risplittare train e test\n",
    "#data = concat_dataset(Train,Test)#unisco, faccio ENCODING e PIPELINE e ridivido\n",
    "#data.reset_index()[data.columns]\n",
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train,Test = encoding_prova(Train,Test,encoder)\n",
    "#Train,Test=lav_dataset(data,numero_righe_train)\n",
    "print(Train.info())\n",
    "print(Test.info())\n",
    "chiavi(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train,y_train =X_train_y_train('No-show') \n",
    "X_test,y_test = X_test_y_test('No-show')\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_end,modello,titolo,X_train,X_test = con_senza_fselection(X_train,y_train,X_test,y_test)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"L'ACCURACY FINALE SCELTA È CON :\",titolo,\"CON UN ACCURACY DEL {0:.{1}f}\".format(accuracy_end*100, 1),\"%\")\n",
    "da_plottare(modello,X_train,y_train,X_test,y_test,titolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
